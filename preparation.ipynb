{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/annotated_sentences500.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Strings to Python Lists**\n",
    "\n",
    " - What happens:\n",
    "\n",
    "The tokens and labels columns in the DataFrame are likely stored as strings (e.g., '[\"token1\", \"token2\"]').\n",
    "The ast.literal_eval function converts these string representations of lists into actual Python lists.\n",
    " - Why this is needed:\n",
    " \n",
    "String representations cannot be processed effectively for NLP tasks; converting them to lists ensures proper handling during tokenization and label alignment.\n",
    " - Result:\n",
    "\n",
    "Both columns, tokens and labels, are now lists of tokens and labels, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tokens  \\\n",
      "0  [There, are, no, Manaslu, between, the, Atlant...   \n",
      "1  [We, were, just, about, to, go, up, in, the, M...   \n",
      "2  [The, quaint, village, is, surrounded, by, Ann...   \n",
      "3  [Ridgway, a, few, more, miles, away, from, the...   \n",
      "4  [He, was, angry, with, her, for, going, up, in...   \n",
      "\n",
      "                                              labels  \n",
      "0  [O, O, O, B-MOUNTAIN, O, O, O, O, O, O, O, O, ...  \n",
      "1  [O, O, O, O, O, O, O, O, O, B-MOUNTAIN, I-MOUN...  \n",
      "2         [O, O, O, O, O, O, B-MOUNTAIN, O, O, O, O]  \n",
      "3  [O, O, O, O, O, O, O, O, O, O, B-MOUNTAIN, I-M...  \n",
      "4   [O, O, O, O, O, O, O, O, O, O, B-MOUNTAIN, O, O]  \n"
     ]
    }
   ],
   "source": [
    "df['tokens'] = df['tokens'].apply(ast.literal_eval)\n",
    "df['labels'] = df['labels'].apply(ast.literal_eval)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the Dataset into Train, Validation, and Test Sets / Print / Save**\n",
    "\n",
    " - What happens:\n",
    "\n",
    "The dataset is split into three subsets:\n",
    "Training set (train_df): Used to train the model.\n",
    "Validation set (val_df): Used to tune hyperparameters and evaluate the model during training.\n",
    "Test set (test_df): Used for final evaluation after training is complete.\n",
    " - The splitting process:\n",
    "\n",
    "The first split separates 70% of the data into the training set and 30% into a temporary set (temp_df).\n",
    "The temporary set is then split equally (50/50) into validation and test sets.\n",
    " - Parameters:\n",
    "\n",
    "test_size=0.30: Reserves 30% of the data for validation and test sets.\n",
    "random_state=42: Ensures reproducibility of the split.\n",
    " - Result:\n",
    " \n",
    "The dataset is divided into three subsets: training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 350\n",
      "Validation size: 75\n",
      "Test size: 75\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42)\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Validation size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))\n",
    "\n",
    "\n",
    "train_df.to_csv(\"data/train.csv\", index=False)\n",
    "val_df.to_csv(\"data/val.csv\", index=False)\n",
    "test_df.to_csv(\"data/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
